{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "928224ef-bffd-46b8-b59d-560a26fec08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import regex as re\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter, OrderedDict, namedtuple\n",
    "import pandas as pd\n",
    "\n",
    "from torchtext.vocab import build_vocab_from_iterator, vocab\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from itertools import chain\n",
    "\n",
    "import nltk\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "# from sklearn.metrics import make_scorer\n",
    "# from sklearn.cross_validation import cross_val_score\n",
    "# from sklearn.grid_search import RandomizedSearchCV\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "\n",
    "\n",
    "##  torch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "## torchtext imports\n",
    "import torchtext\n",
    "from torchtext.vocab import vocab\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "## other imports \n",
    "import io\n",
    "from collections import OrderedDict, Counter\n",
    "import spacy\n",
    "import numpy as np\n",
    "import spacy.cli\n",
    "import random\n",
    "\n",
    "import pycrfsuite\n",
    "from tokenizers import normalizers\n",
    "from tokenizers.normalizers import NFD, StripAccents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "963ebcc5-437d-4a8f-8a44-56518982d21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def accent_normalize(string):\n",
    "#     for char in accents_dict:\n",
    "#         string = re.sub(char, accents_dict[char],string)\n",
    "#     return string\n",
    "\n",
    "normalizer = normalizers.Sequence([NFD(),StripAccents()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13aa174a-412c-4945-a6b7-85da2d6e113b",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = lambda x: re.sub(\"'\",\"\",normalizer.normalize_str(x))\n",
    "\n",
    "START = \"<start>\"\n",
    "END = \"<end>\"\n",
    "UNK = \"<unk>\"\n",
    "PAD = \"<pad>\"\n",
    "BD = \"<bd>\"\n",
    "SPECIALS = [START,END,UNK,PAD, BD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d1f0d13-c1d2-43c8-8024-9b844a87ce4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "langs_codes = {\"Gitksan\": \"git\", \"Arapaho\":\"arp\", \"Lezgi\":\"lez\", \"Nyangbo\":\"nyb\", \"Tsez\":\"ddo\",\"Uspanteko\":\"usp\"}\n",
    "\n",
    "def tag_bd(seq):\n",
    "    for i, c in enumerate(seq):\n",
    "        if c == \"-\":\n",
    "            seq[i] = \"<bd>\"\n",
    "    return seq\n",
    "\n",
    "def get_lang_df(lang):\n",
    "    ld = {\n",
    "        \"train\": defaultdict(list),\n",
    "        \"dev\": defaultdict(list)\n",
    "    }\n",
    "        \n",
    "    path = f\"data/{lang}/\"\n",
    "    train_fn = f\"{langs_codes[lang]}-train-track2-uncovered\"\n",
    "    dev_fn = f\"{langs_codes[lang]}-dev-track2-uncovered\"\n",
    "\n",
    "    for fp in [train_fn, dev_fn]:\n",
    "        data_type = fp.split(\"-\")[1]\n",
    "        with open(path + fp, \"r\") as f:\n",
    "            for line in f.readlines():\n",
    "                \n",
    "\n",
    "                if line.startswith(\"\\\\t\"):\n",
    "                    ld[data_type][\"transcription\"].append(line.lstrip(\"\\\\t \").rstrip(\"\\n\"))\n",
    "                if line.startswith(\"\\g\"):\n",
    "                    ld[data_type][\"glosses\"].append(line.lstrip(\"\\\\g \").rstrip(\"\\n\"))\n",
    "                if line.startswith(\"\\m\"):\n",
    "                    ld[data_type][\"morphemes\"].append(line.lstrip(\"\\\\m \").rstrip(\"\\n\"))\n",
    "\n",
    "                if line.startswith(\"\\l\"):\n",
    "                    ld[data_type][\"translation\"].append(normalize(line.lstrip(\"\\\\l \").rstrip(\"\\n\")))\n",
    "    \n",
    "    train_df = pd.DataFrame.from_dict(ld[\"train\"])\n",
    "    dev_df = pd.DataFrame.from_dict(ld[\"dev\"])\n",
    "    \n",
    "    return ld[\"train\"],ld[\"dev\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e5eed9a-6d5d-463f-9713-f973b60b3a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train,dev=get_lang_df(\"Lezgi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4318579-c164-4605-864c-4601acecd79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_morphs, train_glosses = train[\"morphemes\"], train[\"glosses\"]\n",
    "dev_morphs, dev_glosses = dev[\"morphemes\"], dev[\"glosses\"]\n",
    "\n",
    "def get_segmented(line):\n",
    "    BD = \"#\"\n",
    "    allsplits=[]\n",
    "\n",
    "    splits=[m.split() for m in line]\n",
    "    for i in splits:\n",
    "        for m in i:\n",
    "            allsplits.append(m)\n",
    "    return allsplits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef7d429b-c37c-4537-a360-e887e1c90656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segmented_data(langdict,splits=[\"morphemes\",\"glosses\"]):\n",
    "    data = {}\n",
    "    for split in splits:\n",
    "        data[split] = get_segmented(langdict[split])\n",
    "    return data\n",
    "\n",
    "def get_characterized_data(segments,splits=[\"morphemes\",\"glosses\"]):\n",
    "    data = {}\n",
    "    for split in splits:\n",
    "        data[split] = [[START] + tag_bd(list(m)) + [END] for m in segments[split]]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a47a3a9b-f7d9-4069-9a5d-36e13d39462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed = get_characterized_data(get_segmented_data(train))\n",
    "dev_processed = get_characterized_data(get_segmented_data(dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "041af526-232d-491f-a651-b9faacf5c306",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_data = [(morph, gloss)for morph, gloss in zip(train_processed[\"morphemes\"], train_processed[\"glosses\"])]\n",
    "dev_data = [(morph, gloss)for morph, gloss in zip(dev_processed[\"morphemes\"], dev_processed[\"glosses\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43a7c430-0b40-4d91-b1ff-73c9f2aa608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_split(data, props):\n",
    "    test_data = []\n",
    "    train_data = []\n",
    "    for i, dat in enumerate(data):\n",
    "        if i%props == 0:\n",
    "            test_data.append(dat)\n",
    "        else:\n",
    "            train_data.append(dat)\n",
    "    return test_data, train_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01f80b11-36a5-4012-8405-569d29b0c730",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, train_data = get_train_val_split(train_test_data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efed49b4-0d7e-48a4-92dc-6b7f25799c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = build_vocab_from_iterator(chain(train_morphs,train_glosses), specials = SPECIALS, special_first=True)\n",
    "voc.set_default_index(voc[UNK])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ed22d7a-fb8c-4d10-ad64-893b723cba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def collate_batch(batch):\n",
    "    transform_sequence = lambda x: [voc[c] for c in x]    \n",
    "\n",
    "    input, output = [], []\n",
    "    for morphemes, glosses in batch:\n",
    "        input_tensor = torch.tensor(transform_sequence(morphemes), dtype=torch.long)\n",
    "        output_tensor = torch.tensor(transform_sequence(glosses), dtype=torch.long)\n",
    "        input.append(input_tensor)\n",
    "        output.append(output_tensor)\n",
    "        \n",
    "\n",
    "    return pad_sequence(input, batch_first=False, padding_value=voc[PAD]), pad_sequence(output, batch_first=False, padding_value=voc[PAD])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b782eb83-4940-4321-b255-2a19376ba86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_data, \n",
    "    batch_size=1,\n",
    "    collate_fn=collate_batch,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "dev_dataloader = DataLoader(\n",
    "    dev_data, \n",
    "    batch_size=1,\n",
    "    collate_fn=collate_batch,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_data, \n",
    "    batch_size=1,\n",
    "    collate_fn=collate_batch,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a284b560-ffb5-4bb7-abd3-10c08f39efd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size of source language: torch.Size([12, 1])\n",
      "tensor size of target language: torch.Size([17, 1])\n",
      "the tensor of first example in target language: tensor([ 0, 46,  8,  4, 56, 82, 34,  4, 38, 34, 38,  4, 35, 71, 35, 34,  1])\n",
      "the tensor of first example in src language: tensor([ 0, 77, 28,  4, 19,  7,  4, 54,  4, 19, 11,  1])\n",
      "['<start>', 'ж', 'е', '<bd>', 'д', 'а', '<bd>', 'й', '<bd>', 'д', 'и', '<end>']\n",
      "['<start>', 'b', 'e', '<bd>', 'F', 'U', 'T', '<bd>', 'P', 'T', 'P', '<bd>', 'S', 'B', 'S', 'T', '<end>']\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    src, trg = batch\n",
    "    print('tensor size of source language:', src.shape)\n",
    "    print('tensor size of target language:', trg.shape)\n",
    "    print('the tensor of first example in target language:', trg[:, 0])\n",
    "    print('the tensor of first example in src language:', src[:, 0])\n",
    "    print([voc.get_itos()[i] for i in src[:, 0]])\n",
    "    print([voc.get_itos()[i] for i in trg[:, 0]])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ef55363-b6ff-433d-86bf-84230d7e0195",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from torch.nn import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca4b648-a941-4bc3-909e-dc1f4013174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import Vectors\n",
    "\n",
    "# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
    "\n",
    "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, emb_size, embedding: Vectors):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        #self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.embed = embedding\n",
    "        #self.emb_size = emb_size\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embed(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "# Seq2Seq Network\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers: int,\n",
    "                 num_decoder_layers: int,\n",
    "                 emb_size: int,\n",
    "                 nhead: int,\n",
    "                 src_vocab_size: int,\n",
    "                 tgt_vocab_size: int,\n",
    "                 src_embeddings: nn.Embedding,\n",
    "                 tgt_embeddings: Vectors,\n",
    "                 dim_feedforward: int = 512,\n",
    "                 dropout: float = 0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        self.transformer = Transformer(d_model=emb_size,\n",
    "                                       nhead=nhead,\n",
    "                                       num_encoder_layers=num_encoder_layers,\n",
    "                                       num_decoder_layers=num_decoder_layers,\n",
    "                                       dim_feedforward=dim_feedforward,\n",
    "                                       dropout=dropout)\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(emb_size, src_embeddings)\n",
    "        self.tgt_tok_emb = TokenEmbedding(emb_size, tgt_embeddings)\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self,\n",
    "                src: Tensor,\n",
    "                trg: Tensor,\n",
    "                src_mask: Tensor,\n",
    "                tgt_mask: Tensor,\n",
    "                src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor,\n",
    "                memory_key_padding_mask: Tensor):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
    "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer.encoder(self.positional_encoding(\n",
    "                            self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer.decoder(self.positional_encoding(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e5f1ca-2bff-4a78-8ab8-557b0591dea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3c1bf2-3d31-486a-8cef-be7362aa582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(531)\n",
    "\n",
    "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
    "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
    "EMB_SIZE = 300  # GloVe dim\n",
    "NHEAD = 6\n",
    "FFN_HID_DIM = 512\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "\n",
    "# nn.Embeddings for source language (FR)\n",
    "src_embeddings = nn.Embedding(SRC_VOCAB_SIZE, EMB_SIZE)\n",
    "\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, src_embeddings,\n",
    "                                 tgt_embeddings, FFN_HID_DIM)\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42042eb-94d8-4de0-81d2-4aa67eb9848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_epoch(model, iterator, optimizer):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "\n",
    "    for src, tgt in tqdm(iterator):\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(iterator)\n",
    "\n",
    "\n",
    "def evaluate(model, iterator):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "\n",
    "    for src, tgt in iterator:\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f00f29b-a650-4119-ba3c-d09672c0e7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(transformer, train_dataloader, optimizer)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(transformer, valid_dataloader)\n",
    "\n",
    "    state_dict_model = transformer.state_dict() \n",
    "    state = {\n",
    "        'epoch': epoch,\n",
    "        'state_dict': state_dict_model,\n",
    "        'optimizer': optimizer.state_dict()\n",
    "    }\n",
    "\n",
    "    torch.save(state, \"./drive/MyDrive/Colab Notebooks/ckpt_tut4_emb/transformer_\"+str(epoch) + \".pt\")\n",
    "\n",
    "    print((f\"Epoch: {epoch},  \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {val_loss:.3f} |  Val. PPL: {math.exp(val_loss):7.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

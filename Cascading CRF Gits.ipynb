{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c1469ce-a23b-4200-8108-2dc753e20947",
   "metadata": {},
   "source": [
    "# Cascading CRF for Gitksan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d8c434-d0e3-4bd3-aca1-a903891336d5",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d08210ce-7df9-4e65-8101-cc8be740e67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from itertools import islice\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn_crfsuite import CRF\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn_crfsuite.utils import flatten\n",
    "# import torch\n",
    "# import torch.autograd as autograd\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch.optim as optim "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271881bd-c264-4e1f-9f30-cb125a753283",
   "metadata": {},
   "source": [
    "### Creating a dictionary of orthography, morphemes, gloss (for both training and dev sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "748991ec-a731-48ca-8cea-ddcfe5928b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain_path = \"data/Gitksan/git-train-track2-uncovered\"\n",
    "dev_path = \"data/Gitksan/git-dev-track2-uncovered\"\n",
    "\n",
    "def get_feature_dict(pathname):\n",
    "    gits_dict = defaultdict(list)\n",
    "#     for pathname in paths:\n",
    "#         filetype = pathname.split(\"-\")[-3]\n",
    "    with open(pathname, \"r\") as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"\\\\t\"):\n",
    "                gits_dict[\"orth\"].append(line.lower().lstrip(\"\\\\t \").rstrip(\"\\n\").split(\" \"))\n",
    "            if line.startswith(\"\\\\g\"):\n",
    "                gits_dict[\"gloss\"].append(line.lstrip(\"\\g \").rstrip(\"\\n\").split(\" \"))\n",
    "            if line.startswith(\"\\\\m\"):\n",
    "                gits_dict[\"morphs\"].append(line.lstrip(\"\\m \").rstrip(\"\\n\").split(\" \"))\n",
    "    return gits_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa1ac48a-5d06-4655-b907-c3eeba3326e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gits_train_dict = get_feature_dict(dtrain_path)\n",
    "gits_dev_dict = get_feature_dict(dev_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a20e57a-a9fc-4170-8d85-1e1892f8adcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['orth', 'morphs', 'gloss'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gits_train_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d280422-6fe7-4a24-98d2-9e2afe6c77b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['orth', 'morphs', 'gloss'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gits_dev_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c537b3e1-457f-405a-94ee-8d5356f69ba8",
   "metadata": {},
   "source": [
    "### Getting separate lists for tokens, tags and morphemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b4adb7f-449a-4823-a23e-3b4dc91dc852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_list = list(zip(arp_dict['train_orth'], arp_dict['train_morphs']))\n",
    "# X_train, X_val = train_test_split(train_list, test_size=0.3, random_state=52)\n",
    "# val_input = []\n",
    "# gold_val = []\n",
    "# for orth, morph in X_val:\n",
    "#     val_input.append(orth)\n",
    "#     gold_val.append(morph)\n",
    "# train_input = []\n",
    "# train_morphemes = []\n",
    "# for orth, morph in X_train:\n",
    "#     train_input.append(orth)\n",
    "#     train_morphemes.append([mor.split(\"-\") for mor in morph])  \n",
    "# print(train_input[10], train_morphemes[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd5f6044-4b59-4661-a9da-e807941c6773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "gits_train_tokens, gits_gloss, gits_morphemes = [], [], []\n",
    "gits_train_tokens = list(gits_train_dict[\"orth\"])\n",
    "gits_gloss = list(gits_train_dict[\"gloss\"])\n",
    "gits_morphemes = list(gits_train_dict[\"morphs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "504c9158-4eaf-42a2-bfa0-ac659a62cfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dev\n",
    "gits_dev_tokens = list(gits_dev_dict[\"orth\"])\n",
    "gits_dev_gloss = list(gits_dev_dict[\"gloss\"])\n",
    "gits_dev_morphemes = list(gits_dev_dict[\"morphs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d941be5a-c2c4-4f77-9220-78e8641c1100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ii', 'na', \"'wahl\", \"anhahla'lst\", 'g̲oohl', 'stockholm', 'sawatdiit.'] ['ii', 'n', \"'wa-hl\", \"an-hahla'lst\", 'g̲oo-hl', 'Stockholm', 'si-wa-t-diit']\n",
      "['agwiyukwhl', \"ha'niisgwaa'ytxwhl\", 'g̲an', 'wihl', 'neediit', 'naa', 'ji', \"hahla'ljit.\"] ['agwiyukw-hl', \"ha-'nii-sgwaa'ytxw-hl\", 'g̲an', 'wil-hl', 'nee-dii-t', 'naa', 'ji', \"hahla'lst-it\"]\n"
     ]
    }
   ],
   "source": [
    "print(gits_train_tokens[1], gits_morphemes[1])\n",
    "print(gits_train_tokens[21], gits_morphemes[21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16939033-4683-42d2-bf35-cd7f3bdb290a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "assert len(gits_train_tokens) == len(gits_morphemes) == len(gits_gloss)\n",
    "assert len(gits_dev_tokens) == len(gits_dev_morphemes) == len(gits_dev_gloss)\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8567f4-8959-43d4-b695-acae5043b298",
   "metadata": {},
   "source": [
    "### Feature Engineering for CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6871795b-ea76-4fd5-a30d-434f7336f66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_shape(word):\n",
    "    '''takes in a word and returns the corresponding shape as follows:\n",
    "    for uppercase letters - X\n",
    "    for lowercase letters - x\n",
    "    for digits - d\n",
    "    and keeps punctuations and symbols as is'''\n",
    "    if not word:\n",
    "        return ''\n",
    "    word_shape = []\n",
    "    for char in word:\n",
    "        if char.isupper():\n",
    "            word_shape.append('X')\n",
    "        elif char.islower():\n",
    "            word_shape.append('x')\n",
    "        elif char.isdigit():\n",
    "            word_shape.append('d')\n",
    "        else:\n",
    "            word_shape.append(char)\n",
    "    shape = ''.join(word_shape)\n",
    "    return shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03191905-ee1e-40dd-ab30-682792684d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_short_word_shape(shape):\n",
    "    '''takes in a word shape and returns the corresponding shorter shape as follows by truncating repeating letters'''\n",
    "    if not shape:\n",
    "        return ''\n",
    "    short_shape = []\n",
    "    for x in range(len(shape) - 1):\n",
    "        if shape[x] != shape[x + 1]:\n",
    "            short_shape.append(shape[x])\n",
    "        else:\n",
    "            pass\n",
    "    short_shape.append(shape[-1])\n",
    "    short = ''.join(short_shape)\n",
    "    return short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6f0f15c-8f67-4a23-9725-7d5ac149e092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sentence, morphemes, idx):\n",
    "    word_features = {}\n",
    "    \n",
    "    #Word level features for each word\n",
    "    shape = get_word_shape(sentence[idx])\n",
    "    short_shape = get_short_word_shape(shape)\n",
    "    word_features['word'] = sentence[idx]\n",
    "    word_features['word_isdigit'] = sentence[idx].isdigit()\n",
    "    word_features['word_distance_from_start'] = idx\n",
    "    word_features['word_shape'] = shape\n",
    "    word_features['short_word_shape'] = short_shape\n",
    "    word_features['accent_marker'] = True if \"'\" in sentence[idx] else False\n",
    "    \n",
    "    word_features['word_prefix1'] = sentence[idx][:1]\n",
    "    word_features['word_prefix2'] = sentence[idx][:2]\n",
    "    word_features['word_suffix1'] = sentence[idx][-1:]\n",
    "    word_features['word_suffix2'] = sentence[idx][-2:]\n",
    "    \n",
    "    if len(sentence[idx]) > 4:\n",
    "        word_features['word_prefix3'] = sentence[idx][:3]\n",
    "        word_features['word_prefix4'] = sentence[idx][:4]\n",
    "        word_features['word_suffix3'] = sentence[idx][-3:]\n",
    "        word_features['word_suffix4'] = sentence[idx][-4:]\n",
    "    \n",
    "    # To include features of the previous word\n",
    "    if idx > 0:\n",
    "        word_features['__BOS'] = False\n",
    "        word = sentence[idx-1]\n",
    "        shape = get_word_shape(word)\n",
    "        short_shape = get_short_word_shape(shape)\n",
    "        word_features['previous_word'] = word\n",
    "        word_features['previous_word_distance_from_start'] = idx - 1\n",
    "        word_features['previous_word_shape'] = shape\n",
    "        word_features['previous_short_word_shape'] = short_shape\n",
    "        word_features['previous_accent_marker'] = True if \"'\" in word else False\n",
    "        \n",
    "        word_features['previous_word_prefix1'] = word[:1]\n",
    "        word_features['previous_word_prefix2'] = word[:2]\n",
    "        word_features['previous_word_suffix1'] = word[-1:]\n",
    "        word_features['previous_word_suffix2'] = word[-2:]\n",
    "\n",
    "        if len(word) > 4:\n",
    "            word_features['previous_word_prefix3'] = word[:3]\n",
    "            word_features['previous_word_prefix4'] = word[:4]\n",
    "            word_features['previous_word_suffix3'] = word[-3:]\n",
    "            word_features['previous_word_suffix4'] = word[-4:]\n",
    "\n",
    "    else:\n",
    "        word_features['__BOS'] = True\n",
    "        \n",
    "    # To include features of next word\n",
    "    if idx < len(sentence) - 1:\n",
    "        word_features['__EOS'] = False\n",
    "        word = sentence[idx+1]\n",
    "        shape = get_word_shape(word)\n",
    "        short_shape = get_short_word_shape(shape)\n",
    "        word_features['next_word'] = word\n",
    "        word_features['next_word_distance_from_start'] = idx + 1\n",
    "        word_features['next_word_shape'] = shape\n",
    "        word_features['next_short_word_shape'] = short_shape\n",
    "        word_features['next_accent_marker'] = True if \"'\" in word else False\n",
    "        \n",
    "        word_features['next_word_prefix1'] = word[:1]\n",
    "        word_features['next_word_prefix2'] = word[:2]\n",
    "        word_features['next_word_suffix1'] = word[-1:]\n",
    "        word_features['next_word_suffix2'] = word[-2:]\n",
    "\n",
    "        if len(word) > 4:\n",
    "            word_features['next_word_prefix3'] = word[:3]\n",
    "            word_features['next_word_prefix4'] = word[:4]\n",
    "            word_features['next_word_suffix3'] = word[-3:]\n",
    "            word_features['next_word_suffix4'] = word[-4:]\n",
    "        \n",
    "    else:\n",
    "        word_features['__EOS'] = True\n",
    "        \n",
    "    #Morpheme level features for each word\n",
    "    word_features[\"morpheme\"] = morphemes[idx]\n",
    "    word_features[\"morpheme-struct\"] = morphemes[idx].split(\"-\")\n",
    "    \n",
    "    if idx > 0:\n",
    "        word_features[\"previous_morpheme\"] = morphemes[idx-1]\n",
    "        word_features[\"previous_morpheme-struct\"] = morphemes[idx-1].split(\"-\")\n",
    "    \n",
    "    if idx < len(sentence) - 1:\n",
    "        word_features[\"next_morpheme\"] = morphemes[idx-1]\n",
    "        word_features[\"next_morpheme-struct\"] = morphemes[idx-1].split(\"-\")\n",
    "    \n",
    "    return word_features\n",
    "\n",
    "def sentence2features(sentence, morphemes):\n",
    "    return [word2features(sentence, morphemes, idx) for idx in range(len(sentence))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b87350b7-9170-4304-a899-def9a644837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_ner_feature_dicts(sents, morphs, glosses):\n",
    "    all_dicts = []\n",
    "    all_tags = []\n",
    "    for sent, morph in zip(sents, morphs):\n",
    "        all_dicts.append(sentence2features(sent, morph))\n",
    "    for gloss in glosses:\n",
    "        all_tags.append(gloss)\n",
    "    \n",
    "    return all_dicts, all_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1047877c-813c-44e3-8f1c-5b0cf3e1a4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dicts, train_tags = prepare_ner_feature_dicts(gits_train_tokens, gits_morphemes, gits_gloss)\n",
    "dev_dicts, dev_tags = prepare_ner_feature_dicts(gits_dev_tokens, gits_dev_morphemes, gits_dev_gloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cec11b45-2c9f-46d9-b18b-a08428df8cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(train_dicts) == len(train_tags)\n",
    "assert len(dev_dicts) == len(dev_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c26f407-e126-42ee-bbc2-0b3a883d7828",
   "metadata": {},
   "source": [
    "### Train the CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77fa6caf-d103-4b09-a4d5-c4a2e350945d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|██████| 31/31 [00:00<00:00, 1878.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 27332\n",
      "Seconds required: 0.032\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.100000\n",
      "c2: 0.001000\n",
      "num_memories: 6\n",
      "max_iterations: 200\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "Iter 1   time=0.01  loss=1196.21  active=7673  feature_norm=1.00\n",
      "Iter 2   time=0.01  loss=1108.08  active=7858  feature_norm=1.04\n",
      "Iter 3   time=0.01  loss=1029.24  active=7904  feature_norm=1.59\n",
      "Iter 4   time=0.01  loss=822.47   active=7871  feature_norm=4.35\n",
      "Iter 5   time=0.01  loss=624.79   active=8096  feature_norm=6.48\n",
      "Iter 6   time=0.01  loss=446.86   active=8132  feature_norm=9.32\n",
      "Iter 7   time=0.01  loss=232.22   active=8083  feature_norm=15.27\n",
      "Iter 8   time=0.01  loss=167.15   active=7915  feature_norm=18.15\n",
      "Iter 9   time=0.01  loss=156.31   active=7688  feature_norm=18.72\n",
      "Iter 10  time=0.01  loss=152.96   active=7613  feature_norm=18.78\n",
      "Iter 11  time=0.01  loss=149.19   active=7482  feature_norm=18.61\n",
      "Iter 12  time=0.01  loss=145.52   active=7082  feature_norm=18.26\n",
      "Iter 13  time=0.01  loss=142.05   active=6827  feature_norm=18.02\n",
      "Iter 14  time=0.01  loss=138.61   active=6478  feature_norm=17.80\n",
      "Iter 15  time=0.01  loss=135.99   active=6082  feature_norm=17.80\n",
      "Iter 16  time=0.01  loss=134.01   active=5881  feature_norm=17.98\n",
      "Iter 17  time=0.01  loss=131.73   active=5607  feature_norm=18.46\n",
      "Iter 18  time=0.01  loss=128.91   active=5190  feature_norm=19.68\n",
      "Iter 19  time=0.01  loss=126.80   active=4979  feature_norm=20.77\n",
      "Iter 20  time=0.01  loss=124.96   active=4810  feature_norm=21.70\n",
      "Iter 21  time=0.01  loss=123.58   active=4599  feature_norm=22.32\n",
      "Iter 22  time=0.01  loss=121.29   active=4240  feature_norm=24.96\n",
      "Iter 23  time=0.01  loss=120.28   active=4184  feature_norm=25.29\n",
      "Iter 24  time=0.01  loss=118.83   active=4151  feature_norm=26.13\n",
      "Iter 25  time=0.01  loss=117.88   active=4070  feature_norm=26.86\n",
      "Iter 26  time=0.01  loss=117.29   active=3835  feature_norm=28.75\n",
      "Iter 27  time=0.01  loss=115.97   active=3887  feature_norm=29.80\n",
      "Iter 28  time=0.01  loss=115.49   active=3885  feature_norm=30.45\n",
      "Iter 29  time=0.01  loss=114.67   active=3751  feature_norm=32.22\n",
      "Iter 30  time=0.01  loss=114.39   active=3711  feature_norm=34.74\n",
      "Iter 31  time=0.01  loss=113.48   active=3759  feature_norm=35.12\n",
      "Iter 32  time=0.01  loss=113.17   active=3683  feature_norm=35.58\n",
      "Iter 33  time=0.01  loss=112.83   active=3715  feature_norm=36.45\n",
      "Iter 34  time=0.01  loss=112.52   active=3661  feature_norm=36.98\n",
      "Iter 35  time=0.01  loss=112.27   active=3632  feature_norm=37.62\n",
      "Iter 36  time=0.01  loss=112.03   active=3590  feature_norm=38.11\n",
      "Iter 37  time=0.01  loss=111.85   active=3545  feature_norm=38.64\n",
      "Iter 38  time=0.01  loss=111.66   active=3547  feature_norm=39.01\n",
      "Iter 39  time=0.01  loss=111.50   active=3497  feature_norm=39.36\n",
      "Iter 40  time=0.01  loss=111.35   active=3501  feature_norm=39.54\n",
      "Iter 41  time=0.01  loss=111.14   active=3451  feature_norm=39.76\n",
      "Iter 42  time=0.01  loss=110.95   active=3363  feature_norm=40.13\n",
      "Iter 43  time=0.01  loss=110.75   active=3365  feature_norm=40.34\n",
      "Iter 44  time=0.01  loss=110.65   active=3431  feature_norm=40.34\n",
      "Iter 45  time=0.01  loss=110.56   active=3329  feature_norm=40.36\n",
      "Iter 46  time=0.01  loss=110.46   active=3302  feature_norm=40.46\n",
      "Iter 47  time=0.01  loss=110.40   active=3262  feature_norm=40.47\n",
      "Iter 48  time=0.01  loss=110.31   active=3283  feature_norm=40.56\n",
      "Iter 49  time=0.01  loss=110.25   active=3265  feature_norm=40.60\n",
      "Iter 50  time=0.01  loss=110.18   active=3201  feature_norm=40.71\n",
      "Iter 51  time=0.01  loss=110.13   active=3149  feature_norm=40.71\n",
      "Iter 52  time=0.01  loss=110.09   active=3119  feature_norm=40.83\n",
      "Iter 53  time=0.01  loss=110.05   active=3103  feature_norm=40.82\n",
      "Iter 54  time=0.01  loss=110.00   active=3077  feature_norm=40.86\n",
      "Iter 55  time=0.01  loss=109.95   active=3025  feature_norm=40.80\n",
      "Iter 56  time=0.01  loss=109.92   active=3022  feature_norm=40.93\n",
      "Iter 57  time=0.01  loss=109.86   active=3040  feature_norm=40.92\n",
      "Iter 58  time=0.01  loss=109.82   active=3014  feature_norm=40.90\n",
      "Iter 59  time=0.01  loss=109.78   active=2979  feature_norm=40.90\n",
      "Iter 60  time=0.01  loss=109.75   active=2946  feature_norm=40.92\n",
      "Iter 61  time=0.01  loss=109.71   active=2927  feature_norm=40.92\n",
      "Iter 62  time=0.01  loss=109.68   active=2902  feature_norm=40.93\n",
      "Iter 63  time=0.01  loss=109.65   active=2853  feature_norm=40.93\n",
      "Iter 64  time=0.01  loss=109.62   active=2849  feature_norm=40.93\n",
      "Iter 65  time=0.01  loss=109.60   active=2827  feature_norm=40.94\n",
      "Iter 66  time=0.01  loss=109.57   active=2787  feature_norm=40.95\n",
      "Iter 67  time=0.01  loss=109.55   active=2753  feature_norm=41.00\n",
      "Iter 68  time=0.01  loss=109.51   active=2741  feature_norm=41.01\n",
      "Iter 69  time=0.01  loss=109.50   active=2727  feature_norm=41.01\n",
      "Iter 70  time=0.01  loss=109.47   active=2671  feature_norm=41.01\n",
      "Iter 71  time=0.01  loss=109.45   active=2626  feature_norm=41.04\n",
      "Iter 72  time=0.01  loss=109.43   active=2600  feature_norm=41.06\n",
      "Iter 73  time=0.01  loss=109.42   active=2588  feature_norm=41.09\n",
      "Iter 74  time=0.01  loss=109.40   active=2598  feature_norm=41.09\n",
      "Iter 75  time=0.01  loss=109.38   active=2564  feature_norm=41.12\n",
      "Iter 76  time=0.01  loss=109.37   active=2552  feature_norm=41.13\n",
      "Iter 77  time=0.01  loss=109.36   active=2541  feature_norm=41.17\n",
      "Iter 78  time=0.01  loss=109.35   active=2522  feature_norm=41.18\n",
      "Iter 79  time=0.01  loss=109.34   active=2515  feature_norm=41.19\n",
      "Iter 80  time=0.01  loss=109.32   active=2505  feature_norm=41.20\n",
      "Iter 81  time=0.01  loss=109.31   active=2471  feature_norm=41.20\n",
      "Iter 82  time=0.01  loss=109.30   active=2478  feature_norm=41.26\n",
      "Iter 83  time=0.01  loss=109.29   active=2490  feature_norm=41.25\n",
      "Iter 84  time=0.01  loss=109.28   active=2487  feature_norm=41.27\n",
      "Iter 85  time=0.01  loss=109.27   active=2475  feature_norm=41.29\n",
      "Iter 86  time=0.01  loss=109.26   active=2440  feature_norm=41.33\n",
      "Iter 87  time=0.01  loss=109.25   active=2436  feature_norm=41.36\n",
      "Iter 88  time=0.01  loss=109.25   active=2426  feature_norm=41.37\n",
      "Iter 89  time=0.01  loss=109.24   active=2416  feature_norm=41.40\n",
      "Iter 90  time=0.01  loss=109.23   active=2393  feature_norm=41.45\n",
      "Iter 91  time=0.01  loss=109.23   active=2392  feature_norm=41.51\n",
      "Iter 92  time=0.01  loss=109.21   active=2396  feature_norm=41.54\n",
      "Iter 93  time=0.01  loss=109.21   active=2391  feature_norm=41.56\n",
      "Iter 94  time=0.01  loss=109.20   active=2367  feature_norm=41.60\n",
      "Iter 95  time=0.01  loss=109.19   active=2360  feature_norm=41.64\n",
      "Iter 96  time=0.01  loss=109.19   active=2336  feature_norm=41.70\n",
      "Iter 97  time=0.01  loss=109.18   active=2323  feature_norm=41.74\n",
      "Iter 98  time=0.01  loss=109.17   active=2301  feature_norm=41.76\n",
      "Iter 99  time=0.01  loss=109.17   active=2286  feature_norm=41.78\n",
      "Iter 100 time=0.01  loss=109.16   active=2275  feature_norm=41.79\n",
      "Iter 101 time=0.01  loss=109.16   active=2270  feature_norm=41.82\n",
      "Iter 102 time=0.01  loss=109.16   active=2260  feature_norm=41.84\n",
      "Iter 103 time=0.01  loss=109.15   active=2255  feature_norm=41.87\n",
      "Iter 104 time=0.01  loss=109.15   active=2248  feature_norm=41.88\n",
      "Iter 105 time=0.01  loss=109.15   active=2250  feature_norm=41.91\n",
      "Iter 106 time=0.01  loss=109.15   active=2250  feature_norm=41.93\n",
      "Iter 107 time=0.01  loss=109.14   active=2238  feature_norm=41.96\n",
      "Iter 108 time=0.01  loss=109.14   active=2232  feature_norm=41.97\n",
      "Iter 109 time=0.01  loss=109.14   active=2223  feature_norm=41.99\n",
      "Iter 110 time=0.01  loss=109.14   active=2217  feature_norm=42.00\n",
      "Iter 111 time=0.01  loss=109.13   active=2210  feature_norm=42.02\n",
      "Iter 112 time=0.01  loss=109.13   active=2202  feature_norm=42.03\n",
      "Iter 113 time=0.01  loss=109.13   active=2193  feature_norm=42.05\n",
      "Iter 114 time=0.01  loss=109.13   active=2189  feature_norm=42.06\n",
      "Iter 115 time=0.01  loss=109.12   active=2189  feature_norm=42.09\n",
      "Iter 116 time=0.01  loss=109.12   active=2176  feature_norm=42.10\n",
      "Iter 117 time=0.01  loss=109.12   active=2178  feature_norm=42.13\n",
      "Iter 118 time=0.01  loss=109.12   active=2166  feature_norm=42.14\n",
      "Iter 119 time=0.01  loss=109.11   active=2165  feature_norm=42.17\n",
      "Iter 120 time=0.01  loss=109.11   active=2156  feature_norm=42.17\n",
      "Iter 121 time=0.01  loss=109.11   active=2151  feature_norm=42.18\n",
      "Iter 122 time=0.01  loss=109.11   active=2147  feature_norm=42.19\n",
      "Iter 123 time=0.01  loss=109.10   active=2137  feature_norm=42.21\n",
      "Iter 124 time=0.01  loss=109.10   active=2142  feature_norm=42.23\n",
      "Iter 125 time=0.01  loss=109.10   active=2146  feature_norm=42.24\n",
      "Iter 126 time=0.01  loss=109.09   active=2140  feature_norm=42.24\n",
      "Iter 127 time=0.01  loss=109.09   active=2123  feature_norm=42.26\n",
      "Iter 128 time=0.01  loss=109.09   active=2123  feature_norm=42.27\n",
      "Iter 129 time=0.01  loss=109.09   active=2112  feature_norm=42.28\n",
      "Iter 130 time=0.01  loss=109.08   active=2107  feature_norm=42.29\n",
      "Iter 131 time=0.01  loss=109.08   active=2103  feature_norm=42.29\n",
      "Iter 132 time=0.01  loss=109.08   active=2096  feature_norm=42.30\n",
      "Iter 133 time=0.01  loss=109.08   active=2093  feature_norm=42.32\n",
      "Iter 134 time=0.01  loss=109.08   active=2090  feature_norm=42.33\n",
      "Iter 135 time=0.01  loss=109.08   active=2089  feature_norm=42.34\n",
      "Iter 136 time=0.01  loss=109.08   active=2089  feature_norm=42.35\n",
      "Iter 137 time=0.01  loss=109.07   active=2081  feature_norm=42.36\n",
      "Iter 138 time=0.01  loss=109.07   active=2082  feature_norm=42.37\n",
      "Iter 139 time=0.01  loss=109.07   active=2077  feature_norm=42.38\n",
      "Iter 140 time=0.01  loss=109.07   active=2074  feature_norm=42.39\n",
      "Iter 141 time=0.01  loss=109.07   active=2069  feature_norm=42.41\n",
      "Iter 142 time=0.01  loss=109.07   active=2064  feature_norm=42.42\n",
      "Iter 143 time=0.01  loss=109.06   active=2058  feature_norm=42.42\n",
      "Iter 144 time=0.01  loss=109.06   active=2048  feature_norm=42.43\n",
      "Iter 145 time=0.01  loss=109.06   active=2040  feature_norm=42.43\n",
      "Iter 146 time=0.01  loss=109.06   active=2042  feature_norm=42.44\n",
      "Iter 147 time=0.01  loss=109.06   active=2045  feature_norm=42.46\n",
      "Iter 148 time=0.01  loss=109.06   active=2031  feature_norm=42.46\n",
      "Iter 149 time=0.01  loss=109.05   active=2033  feature_norm=42.47\n",
      "Iter 150 time=0.01  loss=109.05   active=2028  feature_norm=42.47\n",
      "Iter 151 time=0.01  loss=109.05   active=2029  feature_norm=42.49\n",
      "Iter 152 time=0.01  loss=109.05   active=2025  feature_norm=42.49\n",
      "Iter 153 time=0.01  loss=109.05   active=2034  feature_norm=42.51\n",
      "Iter 154 time=0.01  loss=109.05   active=2038  feature_norm=42.51\n",
      "Iter 155 time=0.01  loss=109.05   active=2032  feature_norm=42.52\n",
      "Iter 156 time=0.01  loss=109.05   active=2024  feature_norm=42.52\n",
      "Iter 157 time=0.01  loss=109.05   active=2013  feature_norm=42.53\n",
      "Iter 158 time=0.01  loss=109.05   active=2008  feature_norm=42.53\n",
      "Iter 159 time=0.01  loss=109.05   active=2007  feature_norm=42.54\n",
      "Iter 160 time=0.01  loss=109.05   active=1998  feature_norm=42.55\n",
      "Iter 161 time=0.01  loss=109.04   active=1996  feature_norm=42.56\n",
      "Iter 162 time=0.01  loss=109.04   active=1995  feature_norm=42.56\n",
      "Iter 163 time=0.01  loss=109.04   active=1993  feature_norm=42.57\n",
      "Iter 164 time=0.01  loss=109.04   active=1988  feature_norm=42.57\n",
      "Iter 165 time=0.01  loss=109.04   active=1984  feature_norm=42.58\n",
      "Iter 166 time=0.01  loss=109.04   active=1981  feature_norm=42.58\n",
      "Iter 167 time=0.01  loss=109.04   active=1970  feature_norm=42.59\n",
      "Iter 168 time=0.01  loss=109.04   active=1975  feature_norm=42.59\n",
      "Iter 169 time=0.01  loss=109.04   active=1969  feature_norm=42.60\n",
      "Iter 170 time=0.01  loss=109.04   active=1966  feature_norm=42.60\n",
      "Iter 171 time=0.01  loss=109.04   active=1962  feature_norm=42.60\n",
      "Iter 172 time=0.01  loss=109.04   active=1959  feature_norm=42.61\n",
      "Iter 173 time=0.01  loss=109.04   active=1965  feature_norm=42.61\n",
      "Iter 174 time=0.01  loss=109.04   active=1954  feature_norm=42.61\n",
      "Iter 175 time=0.01  loss=109.04   active=1951  feature_norm=42.62\n",
      "Iter 176 time=0.01  loss=109.04   active=1950  feature_norm=42.62\n",
      "Iter 177 time=0.01  loss=109.04   active=1955  feature_norm=42.63\n",
      "Iter 178 time=0.01  loss=109.04   active=1953  feature_norm=42.63\n",
      "Iter 179 time=0.01  loss=109.04   active=1956  feature_norm=42.64\n",
      "Iter 180 time=0.01  loss=109.03   active=1953  feature_norm=42.64\n",
      "Iter 181 time=0.01  loss=109.03   active=1956  feature_norm=42.65\n",
      "Iter 182 time=0.01  loss=109.03   active=1950  feature_norm=42.65\n",
      "Iter 183 time=0.01  loss=109.03   active=1951  feature_norm=42.65\n",
      "Iter 184 time=0.01  loss=109.03   active=1951  feature_norm=42.65\n",
      "Iter 185 time=0.01  loss=109.03   active=1959  feature_norm=42.66\n",
      "Iter 186 time=0.01  loss=109.03   active=1955  feature_norm=42.66\n",
      "Iter 187 time=0.01  loss=109.03   active=1951  feature_norm=42.66\n",
      "Iter 188 time=0.01  loss=109.03   active=1942  feature_norm=42.66\n",
      "Iter 189 time=0.01  loss=109.03   active=1939  feature_norm=42.67\n",
      "Iter 190 time=0.01  loss=109.03   active=1929  feature_norm=42.67\n",
      "Iter 191 time=0.01  loss=109.03   active=1930  feature_norm=42.67\n",
      "Iter 192 time=0.01  loss=109.03   active=1927  feature_norm=42.67\n",
      "Iter 193 time=0.01  loss=109.03   active=1931  feature_norm=42.67\n",
      "Iter 194 time=0.01  loss=109.03   active=1926  feature_norm=42.67\n",
      "Iter 195 time=0.01  loss=109.03   active=1929  feature_norm=42.68\n",
      "Iter 196 time=0.01  loss=109.03   active=1935  feature_norm=42.68\n",
      "Iter 197 time=0.01  loss=109.03   active=1945  feature_norm=42.69\n",
      "Iter 198 time=0.01  loss=109.03   active=1939  feature_norm=42.69\n",
      "Iter 199 time=0.01  loss=109.03   active=1935  feature_norm=42.70\n",
      "Iter 200 time=0.01  loss=109.03   active=1932  feature_norm=42.70\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 1.314\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 1932 (27332)\n",
      "Number of active attributes: 1530 (2889)\n",
      "Number of active labels: 140 (140)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.004\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crf = CRF(algorithm='lbfgs', verbose=1,c1=0.1, c2=0.001, max_iterations=200, all_possible_transitions=True)\n",
    "\n",
    "try:\n",
    "    crf.fit(train_dicts, train_tags)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce41728-0027-4b3e-b8e2-68b2ce9fe05b",
   "metadata": {},
   "source": [
    "### Test dev predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a65fa09-c083-4ed3-9606-e0442b7e055d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25773195876288657\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = crf.predict(dev_dicts)\n",
    "print(accuracy_score(flatten(dev_tags), flatten(y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d52c1c5-690b-4c1c-be8c-12e4f76b0829",
   "metadata": {},
   "source": [
    "### Building a cascading crf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63d49c7f-9ed0-4af2-88a7-6eb95492cb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "train_copy = deepcopy(train_dicts)\n",
    "\n",
    "for idx in range(len(train_copy)):\n",
    "    for jdx in range(len(train_copy[idx])):\n",
    "        if train_copy[idx][jdx][\"__BOS\"]:\n",
    "            continue\n",
    "        else:\n",
    "            train_copy[idx][jdx][\"prev_prediction\"] = crf.predict_single(train_copy[idx][jdx - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b0b7c451-5a95-4d31-8195-08861365edce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|██████| 31/31 [00:00<00:00, 1448.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 28381\n",
      "Seconds required: 0.027\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.001000\n",
      "c2: 0.001000\n",
      "num_memories: 9\n",
      "max_iterations: 500\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "Iter 1   time=0.03  loss=1283.47  active=28241 feature_norm=0.50\n",
      "Iter 2   time=0.01  loss=1195.31  active=28224 feature_norm=0.36\n",
      "Iter 3   time=0.01  loss=1180.61  active=28232 feature_norm=0.43\n",
      "Iter 4   time=0.01  loss=1152.81  active=28156 feature_norm=0.98\n",
      "Iter 5   time=0.01  loss=1101.04  active=28220 feature_norm=1.00\n",
      "Iter 6   time=0.01  loss=1050.54  active=28230 feature_norm=1.28\n",
      "Iter 7   time=0.01  loss=749.39   active=28128 feature_norm=4.86\n",
      "Iter 8   time=0.01  loss=492.73   active=27567 feature_norm=8.23\n",
      "Iter 9   time=0.01  loss=267.12   active=28135 feature_norm=11.60\n",
      "Iter 10  time=0.01  loss=94.24    active=28156 feature_norm=15.89\n",
      "Iter 11  time=0.01  loss=32.08    active=28157 feature_norm=20.12\n",
      "Iter 12  time=0.01  loss=16.56    active=28180 feature_norm=22.09\n",
      "Iter 13  time=0.01  loss=11.28    active=28213 feature_norm=23.00\n",
      "Iter 14  time=0.01  loss=8.79     active=28221 feature_norm=23.97\n",
      "Iter 15  time=0.01  loss=6.96     active=28229 feature_norm=25.90\n",
      "Iter 16  time=0.01  loss=5.70     active=28212 feature_norm=27.34\n",
      "Iter 17  time=0.01  loss=5.31     active=28227 feature_norm=27.66\n",
      "Iter 18  time=0.01  loss=5.12     active=26777 feature_norm=28.29\n",
      "Iter 19  time=0.01  loss=4.99     active=25504 feature_norm=28.66\n",
      "Iter 20  time=0.01  loss=4.91     active=24635 feature_norm=29.14\n",
      "Iter 21  time=0.01  loss=4.85     active=23445 feature_norm=29.32\n",
      "Iter 22  time=0.01  loss=4.82     active=22515 feature_norm=29.49\n",
      "Iter 23  time=0.01  loss=4.79     active=21893 feature_norm=29.54\n",
      "Iter 24  time=0.01  loss=4.76     active=20868 feature_norm=29.50\n",
      "Iter 25  time=0.01  loss=4.72     active=19930 feature_norm=29.36\n",
      "Iter 26  time=0.01  loss=4.67     active=16956 feature_norm=29.04\n",
      "Iter 27  time=0.01  loss=4.62     active=14075 feature_norm=28.76\n",
      "Iter 28  time=0.01  loss=4.56     active=11762 feature_norm=28.41\n",
      "Iter 29  time=0.01  loss=4.52     active=10718 feature_norm=28.25\n",
      "Iter 30  time=0.01  loss=4.50     active=10118 feature_norm=28.17\n",
      "Iter 31  time=0.01  loss=4.48     active=9660  feature_norm=28.16\n",
      "Iter 32  time=0.01  loss=4.45     active=9250  feature_norm=28.07\n",
      "Iter 33  time=0.01  loss=4.42     active=8803  feature_norm=28.01\n",
      "Iter 34  time=0.01  loss=4.40     active=8579  feature_norm=27.91\n",
      "Iter 35  time=0.01  loss=4.37     active=8380  feature_norm=27.82\n",
      "Iter 36  time=0.01  loss=4.36     active=8282  feature_norm=27.86\n",
      "Iter 37  time=0.01  loss=4.33     active=8021  feature_norm=27.93\n",
      "Iter 38  time=0.01  loss=4.32     active=7879  feature_norm=27.99\n",
      "Iter 39  time=0.01  loss=4.31     active=7604  feature_norm=28.11\n",
      "Iter 40  time=0.01  loss=4.30     active=7442  feature_norm=28.14\n",
      "Iter 41  time=0.01  loss=4.29     active=7369  feature_norm=28.17\n",
      "Iter 42  time=0.01  loss=4.29     active=7271  feature_norm=28.20\n",
      "Iter 43  time=0.01  loss=4.28     active=7215  feature_norm=28.23\n",
      "Iter 44  time=0.01  loss=4.28     active=7199  feature_norm=28.26\n",
      "Iter 45  time=0.01  loss=4.27     active=7179  feature_norm=28.27\n",
      "Iter 46  time=0.01  loss=4.27     active=7152  feature_norm=28.30\n",
      "Iter 47  time=0.01  loss=4.27     active=7091  feature_norm=28.28\n",
      "Iter 48  time=0.01  loss=4.26     active=7090  feature_norm=28.31\n",
      "Iter 49  time=0.01  loss=4.26     active=7084  feature_norm=28.32\n",
      "Iter 50  time=0.01  loss=4.26     active=7092  feature_norm=28.32\n",
      "Iter 51  time=0.01  loss=4.25     active=7058  feature_norm=28.34\n",
      "Iter 52  time=0.01  loss=4.25     active=7043  feature_norm=28.34\n",
      "Iter 53  time=0.01  loss=4.25     active=7036  feature_norm=28.36\n",
      "Iter 54  time=0.01  loss=4.24     active=6997  feature_norm=28.35\n",
      "Iter 55  time=0.01  loss=4.24     active=6970  feature_norm=28.35\n",
      "Iter 56  time=0.01  loss=4.24     active=6905  feature_norm=28.36\n",
      "Iter 57  time=0.01  loss=4.24     active=6830  feature_norm=28.39\n",
      "Iter 58  time=0.01  loss=4.24     active=6831  feature_norm=28.38\n",
      "Iter 59  time=0.01  loss=4.24     active=6842  feature_norm=28.39\n",
      "Iter 60  time=0.01  loss=4.23     active=6824  feature_norm=28.41\n",
      "Iter 61  time=0.01  loss=4.23     active=6794  feature_norm=28.41\n",
      "Iter 62  time=0.01  loss=4.23     active=6752  feature_norm=28.42\n",
      "Iter 63  time=0.01  loss=4.23     active=6734  feature_norm=28.42\n",
      "Iter 64  time=0.01  loss=4.23     active=6736  feature_norm=28.43\n",
      "Iter 65  time=0.01  loss=4.23     active=6727  feature_norm=28.44\n",
      "Iter 66  time=0.01  loss=4.23     active=6702  feature_norm=28.45\n",
      "Iter 67  time=0.01  loss=4.23     active=6694  feature_norm=28.45\n",
      "Iter 68  time=0.01  loss=4.23     active=6690  feature_norm=28.46\n",
      "Iter 69  time=0.01  loss=4.22     active=6705  feature_norm=28.46\n",
      "Iter 70  time=0.01  loss=4.22     active=6706  feature_norm=28.47\n",
      "Iter 71  time=0.01  loss=4.22     active=6699  feature_norm=28.47\n",
      "Iter 72  time=0.01  loss=4.22     active=6660  feature_norm=28.47\n",
      "Iter 73  time=0.01  loss=4.22     active=6636  feature_norm=28.47\n",
      "Iter 74  time=0.01  loss=4.22     active=6653  feature_norm=28.47\n",
      "Iter 75  time=0.01  loss=4.22     active=6627  feature_norm=28.46\n",
      "Iter 76  time=0.01  loss=4.22     active=6635  feature_norm=28.48\n",
      "Iter 77  time=0.01  loss=4.22     active=6638  feature_norm=28.47\n",
      "Iter 78  time=0.01  loss=4.22     active=6635  feature_norm=28.48\n",
      "Iter 79  time=0.01  loss=4.22     active=6610  feature_norm=28.48\n",
      "Iter 80  time=0.01  loss=4.22     active=6634  feature_norm=28.49\n",
      "Iter 81  time=0.01  loss=4.22     active=6636  feature_norm=28.49\n",
      "Iter 82  time=0.01  loss=4.22     active=6638  feature_norm=28.49\n",
      "Iter 83  time=0.01  loss=4.22     active=6634  feature_norm=28.49\n",
      "Iter 84  time=0.01  loss=4.22     active=6629  feature_norm=28.49\n",
      "Iter 85  time=0.01  loss=4.22     active=6627  feature_norm=28.49\n",
      "Iter 86  time=0.01  loss=4.22     active=6613  feature_norm=28.49\n",
      "Iter 87  time=0.01  loss=4.22     active=6598  feature_norm=28.49\n",
      "Iter 88  time=0.01  loss=4.22     active=6577  feature_norm=28.50\n",
      "Iter 89  time=0.01  loss=4.22     active=6569  feature_norm=28.50\n",
      "Iter 90  time=0.01  loss=4.22     active=6571  feature_norm=28.50\n",
      "Iter 91  time=0.01  loss=4.22     active=6572  feature_norm=28.50\n",
      "Iter 92  time=0.01  loss=4.21     active=6555  feature_norm=28.50\n",
      "Iter 93  time=0.01  loss=4.21     active=6550  feature_norm=28.50\n",
      "Iter 94  time=0.01  loss=4.21     active=6538  feature_norm=28.50\n",
      "Iter 95  time=0.01  loss=4.21     active=6551  feature_norm=28.50\n",
      "Iter 96  time=0.01  loss=4.21     active=6534  feature_norm=28.51\n",
      "Iter 97  time=0.01  loss=4.21     active=6524  feature_norm=28.50\n",
      "Iter 98  time=0.01  loss=4.21     active=6518  feature_norm=28.50\n",
      "Iter 99  time=0.01  loss=4.21     active=6501  feature_norm=28.50\n",
      "Iter 100 time=0.01  loss=4.21     active=6489  feature_norm=28.50\n",
      "Iter 101 time=0.01  loss=4.21     active=6501  feature_norm=28.51\n",
      "Iter 102 time=0.01  loss=4.21     active=6516  feature_norm=28.51\n",
      "Iter 103 time=0.01  loss=4.21     active=6519  feature_norm=28.51\n",
      "Iter 104 time=0.01  loss=4.21     active=6521  feature_norm=28.51\n",
      "Iter 105 time=0.01  loss=4.21     active=6529  feature_norm=28.52\n",
      "Iter 106 time=0.01  loss=4.21     active=6516  feature_norm=28.51\n",
      "Iter 107 time=0.01  loss=4.21     active=6513  feature_norm=28.52\n",
      "Iter 108 time=0.01  loss=4.21     active=6529  feature_norm=28.52\n",
      "Iter 109 time=0.01  loss=4.21     active=6526  feature_norm=28.52\n",
      "Iter 110 time=0.01  loss=4.21     active=6513  feature_norm=28.52\n",
      "Iter 111 time=0.01  loss=4.21     active=6515  feature_norm=28.52\n",
      "Iter 112 time=0.01  loss=4.21     active=6515  feature_norm=28.51\n",
      "Iter 113 time=0.01  loss=4.21     active=6513  feature_norm=28.51\n",
      "Iter 114 time=0.01  loss=4.21     active=6498  feature_norm=28.51\n",
      "Iter 115 time=0.01  loss=4.21     active=6483  feature_norm=28.51\n",
      "Iter 116 time=0.01  loss=4.21     active=6489  feature_norm=28.51\n",
      "Iter 117 time=0.01  loss=4.21     active=6488  feature_norm=28.51\n",
      "Iter 118 time=0.01  loss=4.21     active=6482  feature_norm=28.51\n",
      "Iter 119 time=0.01  loss=4.21     active=6478  feature_norm=28.51\n",
      "Iter 120 time=0.01  loss=4.21     active=6477  feature_norm=28.51\n",
      "Iter 121 time=0.01  loss=4.21     active=6467  feature_norm=28.51\n",
      "Iter 122 time=0.01  loss=4.21     active=6483  feature_norm=28.51\n",
      "Iter 123 time=0.01  loss=4.21     active=6476  feature_norm=28.51\n",
      "Iter 124 time=0.01  loss=4.21     active=6485  feature_norm=28.51\n",
      "Iter 125 time=0.01  loss=4.21     active=6484  feature_norm=28.51\n",
      "Iter 126 time=0.01  loss=4.21     active=6475  feature_norm=28.51\n",
      "Iter 127 time=0.01  loss=4.21     active=6451  feature_norm=28.51\n",
      "Iter 128 time=0.01  loss=4.21     active=6452  feature_norm=28.51\n",
      "Iter 129 time=0.01  loss=4.21     active=6447  feature_norm=28.51\n",
      "Iter 130 time=0.01  loss=4.21     active=6446  feature_norm=28.51\n",
      "Iter 131 time=0.01  loss=4.21     active=6438  feature_norm=28.51\n",
      "Iter 132 time=0.01  loss=4.21     active=6422  feature_norm=28.51\n",
      "Iter 133 time=0.01  loss=4.21     active=6407  feature_norm=28.51\n",
      "Iter 134 time=0.01  loss=4.21     active=6400  feature_norm=28.51\n",
      "Iter 135 time=0.01  loss=4.21     active=6397  feature_norm=28.51\n",
      "Iter 136 time=0.01  loss=4.21     active=6405  feature_norm=28.51\n",
      "Iter 137 time=0.01  loss=4.21     active=6405  feature_norm=28.51\n",
      "Iter 138 time=0.01  loss=4.21     active=6404  feature_norm=28.51\n",
      "Iter 139 time=0.01  loss=4.21     active=6408  feature_norm=28.51\n",
      "Iter 140 time=0.01  loss=4.21     active=6407  feature_norm=28.51\n",
      "Iter 141 time=0.01  loss=4.21     active=6408  feature_norm=28.51\n",
      "Iter 142 time=0.01  loss=4.21     active=6394  feature_norm=28.51\n",
      "Iter 143 time=0.01  loss=4.21     active=6381  feature_norm=28.51\n",
      "Iter 144 time=0.01  loss=4.21     active=6381  feature_norm=28.51\n",
      "Iter 145 time=0.02  loss=4.21     active=6386  feature_norm=28.51\n",
      "Iter 146 time=0.02  loss=4.21     active=6379  feature_norm=28.51\n",
      "Iter 147 time=0.02  loss=4.21     active=6369  feature_norm=28.50\n",
      "Iter 148 time=0.02  loss=4.21     active=6370  feature_norm=28.51\n",
      "Iter 149 time=0.02  loss=4.21     active=6368  feature_norm=28.50\n",
      "Iter 150 time=0.02  loss=4.21     active=6359  feature_norm=28.50\n",
      "Iter 151 time=0.02  loss=4.21     active=6362  feature_norm=28.50\n",
      "Iter 152 time=0.02  loss=4.21     active=6340  feature_norm=28.50\n",
      "Iter 153 time=0.02  loss=4.21     active=6341  feature_norm=28.50\n",
      "Iter 154 time=0.02  loss=4.21     active=6331  feature_norm=28.50\n",
      "Iter 155 time=0.02  loss=4.21     active=6329  feature_norm=28.50\n",
      "Iter 156 time=0.02  loss=4.21     active=6329  feature_norm=28.50\n",
      "Iter 157 time=0.02  loss=4.21     active=6331  feature_norm=28.50\n",
      "Iter 158 time=0.02  loss=4.21     active=6325  feature_norm=28.50\n",
      "Iter 159 time=0.02  loss=4.21     active=6325  feature_norm=28.50\n",
      "Iter 160 time=0.02  loss=4.21     active=6327  feature_norm=28.50\n",
      "Iter 161 time=0.02  loss=4.21     active=6336  feature_norm=28.50\n",
      "Iter 162 time=0.02  loss=4.21     active=6332  feature_norm=28.50\n",
      "Iter 163 time=0.02  loss=4.21     active=6326  feature_norm=28.50\n",
      "Iter 164 time=0.02  loss=4.21     active=6327  feature_norm=28.50\n",
      "Iter 165 time=0.02  loss=4.21     active=6325  feature_norm=28.50\n",
      "Iter 166 time=0.02  loss=4.21     active=6325  feature_norm=28.50\n",
      "Iter 167 time=0.02  loss=4.21     active=6325  feature_norm=28.50\n",
      "Iter 168 time=0.02  loss=4.21     active=6332  feature_norm=28.50\n",
      "Iter 169 time=0.02  loss=4.21     active=6323  feature_norm=28.50\n",
      "Iter 170 time=0.02  loss=4.21     active=6317  feature_norm=28.50\n",
      "Iter 171 time=0.02  loss=4.21     active=6317  feature_norm=28.50\n",
      "Iter 172 time=0.02  loss=4.21     active=6311  feature_norm=28.50\n",
      "Iter 173 time=0.02  loss=4.21     active=6310  feature_norm=28.50\n",
      "Iter 174 time=0.02  loss=4.20     active=6323  feature_norm=28.50\n",
      "Iter 175 time=0.02  loss=4.20     active=6319  feature_norm=28.50\n",
      "Iter 176 time=0.02  loss=4.20     active=6317  feature_norm=28.50\n",
      "Iter 177 time=0.02  loss=4.20     active=6326  feature_norm=28.50\n",
      "Iter 178 time=0.02  loss=4.20     active=6324  feature_norm=28.50\n",
      "Iter 179 time=0.02  loss=4.20     active=6320  feature_norm=28.50\n",
      "Iter 180 time=0.02  loss=4.20     active=6311  feature_norm=28.50\n",
      "Iter 181 time=0.02  loss=4.20     active=6329  feature_norm=28.50\n",
      "Iter 182 time=0.02  loss=4.20     active=6329  feature_norm=28.50\n",
      "Iter 183 time=0.02  loss=4.20     active=6337  feature_norm=28.50\n",
      "Iter 184 time=0.02  loss=4.20     active=6331  feature_norm=28.50\n",
      "Iter 185 time=0.02  loss=4.20     active=6333  feature_norm=28.50\n",
      "Iter 186 time=0.02  loss=4.20     active=6325  feature_norm=28.50\n",
      "Iter 187 time=0.02  loss=4.20     active=6317  feature_norm=28.50\n",
      "Iter 188 time=0.02  loss=4.20     active=6315  feature_norm=28.50\n",
      "Iter 189 time=0.02  loss=4.20     active=6309  feature_norm=28.50\n",
      "Iter 190 time=0.02  loss=4.20     active=6311  feature_norm=28.51\n",
      "Iter 191 time=0.02  loss=4.20     active=6313  feature_norm=28.51\n",
      "Iter 192 time=0.02  loss=4.20     active=6311  feature_norm=28.51\n",
      "Iter 193 time=0.02  loss=4.20     active=6314  feature_norm=28.51\n",
      "Iter 194 time=0.02  loss=4.20     active=6312  feature_norm=28.51\n",
      "Iter 195 time=0.02  loss=4.20     active=6314  feature_norm=28.51\n",
      "Iter 196 time=0.02  loss=4.20     active=6317  feature_norm=28.51\n",
      "Iter 197 time=0.02  loss=4.20     active=6327  feature_norm=28.51\n",
      "Iter 198 time=0.02  loss=4.20     active=6333  feature_norm=28.51\n",
      "Iter 199 time=0.02  loss=4.20     active=6332  feature_norm=28.51\n",
      "Iter 200 time=0.02  loss=4.20     active=6323  feature_norm=28.51\n",
      "Iter 201 time=0.02  loss=4.20     active=6322  feature_norm=28.51\n",
      "Iter 202 time=0.02  loss=4.20     active=6323  feature_norm=28.51\n",
      "Iter 203 time=0.02  loss=4.20     active=6335  feature_norm=28.51\n",
      "Iter 204 time=0.02  loss=4.20     active=6331  feature_norm=28.51\n",
      "Iter 205 time=0.02  loss=4.20     active=6320  feature_norm=28.51\n",
      "Iter 206 time=0.02  loss=4.20     active=6313  feature_norm=28.51\n",
      "Iter 207 time=0.02  loss=4.20     active=6305  feature_norm=28.51\n",
      "Iter 208 time=0.02  loss=4.20     active=6301  feature_norm=28.51\n",
      "Iter 209 time=0.02  loss=4.20     active=6306  feature_norm=28.51\n",
      "Iter 210 time=0.02  loss=4.20     active=6306  feature_norm=28.51\n",
      "Iter 211 time=0.02  loss=4.20     active=6304  feature_norm=28.51\n",
      "Iter 212 time=0.02  loss=4.20     active=6307  feature_norm=28.51\n",
      "Iter 213 time=0.02  loss=4.20     active=6304  feature_norm=28.51\n",
      "Iter 214 time=0.02  loss=4.20     active=6302  feature_norm=28.51\n",
      "Iter 215 time=0.02  loss=4.20     active=6289  feature_norm=28.51\n",
      "Iter 216 time=0.02  loss=4.20     active=6288  feature_norm=28.51\n",
      "Iter 217 time=0.02  loss=4.20     active=6279  feature_norm=28.51\n",
      "Iter 218 time=0.02  loss=4.20     active=6279  feature_norm=28.51\n",
      "Iter 219 time=0.02  loss=4.20     active=6277  feature_norm=28.51\n",
      "Iter 220 time=0.02  loss=4.20     active=6269  feature_norm=28.51\n",
      "Iter 221 time=0.02  loss=4.20     active=6253  feature_norm=28.51\n",
      "Iter 222 time=0.02  loss=4.20     active=6251  feature_norm=28.51\n",
      "Iter 223 time=0.02  loss=4.20     active=6253  feature_norm=28.51\n",
      "Iter 224 time=0.02  loss=4.20     active=6256  feature_norm=28.51\n",
      "Iter 225 time=0.02  loss=4.20     active=6256  feature_norm=28.51\n",
      "Iter 226 time=0.02  loss=4.20     active=6250  feature_norm=28.51\n",
      "Iter 227 time=0.02  loss=4.20     active=6246  feature_norm=28.51\n",
      "Iter 228 time=0.02  loss=4.20     active=6245  feature_norm=28.51\n",
      "Iter 229 time=0.02  loss=4.20     active=6249  feature_norm=28.51\n",
      "Iter 230 time=0.02  loss=4.20     active=6248  feature_norm=28.51\n",
      "Iter 231 time=0.02  loss=4.20     active=6241  feature_norm=28.51\n",
      "Iter 232 time=0.02  loss=4.20     active=6235  feature_norm=28.51\n",
      "Iter 233 time=0.02  loss=4.20     active=6231  feature_norm=28.51\n",
      "Iter 234 time=0.02  loss=4.20     active=6230  feature_norm=28.51\n",
      "Iter 235 time=0.02  loss=4.20     active=6228  feature_norm=28.51\n",
      "Iter 236 time=0.02  loss=4.20     active=6228  feature_norm=28.51\n",
      "Iter 237 time=0.02  loss=4.20     active=6230  feature_norm=28.51\n",
      "Iter 238 time=0.02  loss=4.20     active=6228  feature_norm=28.51\n",
      "Iter 239 time=0.02  loss=4.20     active=6227  feature_norm=28.51\n",
      "Iter 240 time=0.02  loss=4.20     active=6222  feature_norm=28.51\n",
      "Iter 241 time=0.02  loss=4.20     active=6222  feature_norm=28.51\n",
      "Iter 242 time=0.02  loss=4.20     active=6219  feature_norm=28.51\n",
      "Iter 243 time=0.02  loss=4.20     active=6217  feature_norm=28.51\n",
      "Iter 244 time=0.02  loss=4.20     active=6230  feature_norm=28.51\n",
      "Iter 245 time=0.02  loss=4.20     active=6231  feature_norm=28.51\n",
      "Iter 246 time=0.02  loss=4.20     active=6231  feature_norm=28.51\n",
      "Iter 247 time=0.02  loss=4.20     active=6226  feature_norm=28.51\n",
      "Iter 248 time=0.02  loss=4.20     active=6227  feature_norm=28.51\n",
      "Iter 249 time=0.02  loss=4.20     active=6227  feature_norm=28.51\n",
      "Iter 250 time=0.02  loss=4.20     active=6223  feature_norm=28.51\n",
      "Iter 251 time=0.02  loss=4.20     active=6221  feature_norm=28.51\n",
      "Iter 252 time=0.02  loss=4.20     active=6220  feature_norm=28.50\n",
      "Iter 253 time=0.02  loss=4.20     active=6219  feature_norm=28.50\n",
      "Iter 254 time=0.02  loss=4.20     active=6220  feature_norm=28.50\n",
      "Iter 255 time=0.02  loss=4.20     active=6217  feature_norm=28.50\n",
      "Iter 256 time=0.02  loss=4.20     active=6209  feature_norm=28.50\n",
      "Iter 257 time=0.02  loss=4.20     active=6211  feature_norm=28.50\n",
      "Iter 258 time=0.02  loss=4.20     active=6220  feature_norm=28.50\n",
      "Iter 259 time=0.02  loss=4.20     active=6222  feature_norm=28.50\n",
      "Iter 260 time=0.02  loss=4.20     active=6223  feature_norm=28.50\n",
      "Iter 261 time=0.02  loss=4.20     active=6222  feature_norm=28.50\n",
      "Iter 262 time=0.02  loss=4.20     active=6215  feature_norm=28.50\n",
      "Iter 263 time=0.02  loss=4.20     active=6217  feature_norm=28.50\n",
      "Iter 264 time=0.02  loss=4.20     active=6217  feature_norm=28.50\n",
      "Iter 265 time=0.02  loss=4.20     active=6213  feature_norm=28.50\n",
      "Iter 266 time=0.02  loss=4.20     active=6211  feature_norm=28.50\n",
      "Iter 267 time=0.02  loss=4.20     active=6213  feature_norm=28.50\n",
      "Iter 268 time=0.02  loss=4.20     active=6221  feature_norm=28.49\n",
      "Iter 269 time=0.02  loss=4.20     active=6222  feature_norm=28.49\n",
      "Iter 270 time=0.02  loss=4.20     active=6223  feature_norm=28.49\n",
      "Iter 271 time=0.02  loss=4.20     active=6219  feature_norm=28.49\n",
      "Iter 272 time=0.02  loss=4.20     active=6228  feature_norm=28.49\n",
      "Iter 273 time=0.02  loss=4.20     active=6226  feature_norm=28.49\n",
      "Iter 274 time=0.02  loss=4.20     active=6226  feature_norm=28.49\n",
      "Iter 275 time=0.02  loss=4.20     active=6220  feature_norm=28.49\n",
      "Iter 276 time=0.02  loss=4.20     active=6223  feature_norm=28.49\n",
      "Iter 277 time=0.02  loss=4.20     active=6223  feature_norm=28.49\n",
      "Iter 278 time=0.02  loss=4.20     active=6219  feature_norm=28.49\n",
      "Iter 279 time=0.02  loss=4.20     active=6218  feature_norm=28.49\n",
      "Iter 280 time=0.02  loss=4.20     active=6218  feature_norm=28.49\n",
      "Iter 281 time=0.02  loss=4.20     active=6217  feature_norm=28.49\n",
      "Iter 282 time=0.02  loss=4.20     active=6209  feature_norm=28.49\n",
      "Iter 283 time=0.02  loss=4.20     active=6208  feature_norm=28.49\n",
      "Iter 284 time=0.02  loss=4.20     active=6207  feature_norm=28.49\n",
      "Iter 285 time=0.02  loss=4.20     active=6213  feature_norm=28.49\n",
      "Iter 286 time=0.02  loss=4.20     active=6213  feature_norm=28.49\n",
      "Iter 287 time=0.02  loss=4.20     active=6207  feature_norm=28.49\n",
      "Iter 288 time=0.02  loss=4.20     active=6206  feature_norm=28.49\n",
      "Iter 289 time=0.02  loss=4.20     active=6205  feature_norm=28.49\n",
      "Iter 290 time=0.02  loss=4.20     active=6207  feature_norm=28.49\n",
      "Iter 291 time=0.02  loss=4.20     active=6211  feature_norm=28.49\n",
      "Iter 292 time=0.02  loss=4.20     active=6208  feature_norm=28.49\n",
      "Iter 293 time=0.02  loss=4.20     active=6209  feature_norm=28.49\n",
      "Iter 294 time=0.02  loss=4.20     active=6208  feature_norm=28.49\n",
      "Iter 295 time=0.02  loss=4.20     active=6207  feature_norm=28.49\n",
      "Iter 296 time=0.02  loss=4.20     active=6207  feature_norm=28.49\n",
      "Iter 297 time=0.02  loss=4.20     active=6204  feature_norm=28.49\n",
      "Iter 298 time=0.02  loss=4.20     active=6202  feature_norm=28.49\n",
      "Iter 299 time=0.02  loss=4.20     active=6202  feature_norm=28.49\n",
      "Iter 300 time=0.02  loss=4.20     active=6198  feature_norm=28.49\n",
      "Iter 301 time=0.02  loss=4.20     active=6203  feature_norm=28.49\n",
      "Iter 302 time=0.02  loss=4.20     active=6203  feature_norm=28.49\n",
      "Iter 303 time=0.02  loss=4.20     active=6202  feature_norm=28.49\n",
      "Iter 304 time=0.02  loss=4.20     active=6200  feature_norm=28.49\n",
      "Iter 305 time=0.02  loss=4.20     active=6208  feature_norm=28.49\n",
      "Iter 306 time=0.02  loss=4.20     active=6207  feature_norm=28.49\n",
      "Iter 307 time=0.02  loss=4.20     active=6208  feature_norm=28.49\n",
      "Iter 308 time=0.02  loss=4.20     active=6208  feature_norm=28.49\n",
      "Iter 309 time=0.02  loss=4.20     active=6200  feature_norm=28.49\n",
      "Iter 310 time=0.02  loss=4.20     active=6200  feature_norm=28.50\n",
      "Iter 311 time=0.02  loss=4.20     active=6198  feature_norm=28.50\n",
      "Iter 312 time=0.02  loss=4.20     active=6197  feature_norm=28.50\n",
      "Iter 313 time=0.02  loss=4.20     active=6198  feature_norm=28.50\n",
      "Iter 314 time=0.02  loss=4.20     active=6198  feature_norm=28.50\n",
      "Iter 315 time=0.02  loss=4.20     active=6198  feature_norm=28.50\n",
      "Iter 316 time=0.02  loss=4.20     active=6197  feature_norm=28.50\n",
      "Iter 317 time=0.02  loss=4.20     active=6194  feature_norm=28.50\n",
      "Iter 318 time=0.02  loss=4.20     active=6192  feature_norm=28.50\n",
      "Iter 319 time=0.02  loss=4.20     active=6192  feature_norm=28.50\n",
      "Iter 320 time=0.02  loss=4.20     active=6192  feature_norm=28.50\n",
      "Iter 321 time=0.02  loss=4.20     active=6186  feature_norm=28.50\n",
      "Iter 322 time=0.02  loss=4.20     active=6180  feature_norm=28.50\n",
      "Iter 323 time=0.02  loss=4.20     active=6180  feature_norm=28.51\n",
      "Iter 324 time=0.02  loss=4.20     active=6181  feature_norm=28.51\n",
      "Iter 325 time=0.02  loss=4.20     active=6182  feature_norm=28.51\n",
      "Iter 326 time=0.02  loss=4.20     active=6181  feature_norm=28.51\n",
      "Iter 327 time=0.02  loss=4.20     active=6182  feature_norm=28.51\n",
      "Iter 328 time=0.02  loss=4.20     active=6187  feature_norm=28.51\n",
      "Iter 329 time=0.02  loss=4.20     active=6180  feature_norm=28.51\n",
      "Iter 330 time=0.02  loss=4.20     active=6173  feature_norm=28.51\n",
      "Iter 331 time=0.02  loss=4.20     active=6180  feature_norm=28.51\n",
      "Iter 332 time=0.02  loss=4.20     active=6180  feature_norm=28.51\n",
      "Iter 333 time=0.02  loss=4.20     active=6174  feature_norm=28.51\n",
      "Iter 334 time=0.02  loss=4.20     active=6178  feature_norm=28.51\n",
      "Iter 335 time=0.02  loss=4.20     active=6173  feature_norm=28.51\n",
      "Iter 336 time=0.02  loss=4.20     active=6173  feature_norm=28.51\n",
      "Iter 337 time=0.02  loss=4.20     active=6170  feature_norm=28.51\n",
      "Iter 338 time=0.02  loss=4.20     active=6166  feature_norm=28.51\n",
      "Iter 339 time=0.02  loss=4.20     active=6163  feature_norm=28.51\n",
      "Iter 340 time=0.02  loss=4.20     active=6162  feature_norm=28.51\n",
      "Iter 341 time=0.02  loss=4.20     active=6160  feature_norm=28.51\n",
      "Iter 342 time=0.02  loss=4.20     active=6160  feature_norm=28.51\n",
      "Iter 343 time=0.02  loss=4.20     active=6164  feature_norm=28.51\n",
      "Iter 344 time=0.02  loss=4.20     active=6163  feature_norm=28.51\n",
      "Iter 345 time=0.02  loss=4.20     active=6164  feature_norm=28.50\n",
      "Iter 346 time=0.01  loss=4.20     active=6157  feature_norm=28.50\n",
      "Iter 347 time=0.01  loss=4.20     active=6167  feature_norm=28.50\n",
      "Iter 348 time=0.02  loss=4.20     active=6179  feature_norm=28.50\n",
      "Iter 349 time=0.02  loss=4.20     active=6181  feature_norm=28.50\n",
      "Iter 350 time=0.02  loss=4.20     active=6180  feature_norm=28.50\n",
      "Iter 351 time=0.02  loss=4.20     active=6182  feature_norm=28.50\n",
      "Iter 352 time=0.02  loss=4.20     active=6183  feature_norm=28.50\n",
      "Iter 353 time=0.02  loss=4.20     active=6180  feature_norm=28.50\n",
      "Iter 354 time=0.02  loss=4.20     active=6177  feature_norm=28.50\n",
      "Iter 355 time=0.02  loss=4.20     active=6177  feature_norm=28.50\n",
      "Iter 356 time=0.02  loss=4.20     active=6176  feature_norm=28.50\n",
      "Iter 357 time=0.01  loss=4.20     active=6174  feature_norm=28.50\n",
      "Iter 358 time=0.02  loss=4.20     active=6177  feature_norm=28.50\n",
      "Iter 359 time=0.02  loss=4.20     active=6177  feature_norm=28.50\n",
      "Iter 360 time=0.02  loss=4.20     active=6175  feature_norm=28.50\n",
      "Iter 361 time=0.02  loss=4.20     active=6175  feature_norm=28.50\n",
      "Iter 362 time=0.02  loss=4.20     active=6178  feature_norm=28.50\n",
      "Iter 363 time=0.02  loss=4.20     active=6178  feature_norm=28.50\n",
      "Iter 364 time=0.02  loss=4.20     active=6170  feature_norm=28.50\n",
      "Iter 365 time=0.02  loss=4.20     active=6163  feature_norm=28.50\n",
      "Iter 366 time=0.02  loss=4.20     active=6161  feature_norm=28.50\n",
      "Iter 367 time=0.02  loss=4.20     active=6161  feature_norm=28.50\n",
      "Iter 368 time=0.02  loss=4.20     active=6162  feature_norm=28.50\n",
      "Iter 369 time=0.02  loss=4.20     active=6163  feature_norm=28.50\n",
      "Iter 370 time=0.02  loss=4.20     active=6163  feature_norm=28.50\n",
      "Iter 371 time=0.02  loss=4.20     active=6162  feature_norm=28.50\n",
      "Iter 372 time=0.02  loss=4.20     active=6151  feature_norm=28.50\n",
      "Iter 373 time=0.02  loss=4.20     active=6150  feature_norm=28.50\n",
      "Iter 374 time=0.02  loss=4.20     active=6157  feature_norm=28.50\n",
      "Iter 375 time=0.02  loss=4.20     active=6156  feature_norm=28.50\n",
      "Iter 376 time=0.01  loss=4.20     active=6154  feature_norm=28.50\n",
      "Iter 377 time=0.02  loss=4.20     active=6155  feature_norm=28.50\n",
      "Iter 378 time=0.02  loss=4.20     active=6155  feature_norm=28.50\n",
      "Iter 379 time=0.02  loss=4.20     active=6156  feature_norm=28.50\n",
      "Iter 380 time=0.02  loss=4.20     active=6157  feature_norm=28.50\n",
      "Iter 381 time=0.02  loss=4.20     active=6163  feature_norm=28.50\n",
      "Iter 382 time=0.02  loss=4.20     active=6163  feature_norm=28.50\n",
      "Iter 383 time=0.02  loss=4.20     active=6158  feature_norm=28.50\n",
      "Iter 384 time=0.02  loss=4.20     active=6156  feature_norm=28.50\n",
      "Iter 385 time=0.02  loss=4.20     active=6157  feature_norm=28.50\n",
      "Iter 386 time=0.02  loss=4.20     active=6157  feature_norm=28.50\n",
      "Iter 387 time=0.02  loss=4.20     active=6159  feature_norm=28.50\n",
      "Iter 388 time=0.02  loss=4.20     active=6158  feature_norm=28.50\n",
      "Iter 389 time=0.02  loss=4.20     active=6151  feature_norm=28.50\n",
      "Iter 390 time=0.02  loss=4.20     active=6151  feature_norm=28.50\n",
      "Iter 391 time=0.02  loss=4.20     active=6150  feature_norm=28.50\n",
      "Iter 392 time=0.02  loss=4.20     active=6150  feature_norm=28.50\n",
      "Iter 393 time=0.02  loss=4.20     active=6150  feature_norm=28.50\n",
      "Iter 394 time=0.02  loss=4.20     active=6149  feature_norm=28.50\n",
      "Iter 395 time=0.02  loss=4.20     active=6151  feature_norm=28.50\n",
      "Iter 396 time=0.02  loss=4.20     active=6152  feature_norm=28.50\n",
      "Iter 397 time=0.02  loss=4.20     active=6150  feature_norm=28.50\n",
      "Iter 398 time=0.02  loss=4.20     active=6151  feature_norm=28.50\n",
      "Iter 399 time=0.02  loss=4.20     active=6151  feature_norm=28.50\n",
      "Iter 400 time=0.02  loss=4.20     active=6151  feature_norm=28.50\n",
      "Iter 401 time=0.02  loss=4.20     active=6151  feature_norm=28.50\n",
      "Iter 402 time=0.02  loss=4.20     active=6152  feature_norm=28.50\n",
      "Iter 403 time=0.02  loss=4.20     active=6152  feature_norm=28.50\n",
      "Iter 404 time=0.02  loss=4.20     active=6151  feature_norm=28.50\n",
      "Iter 405 time=0.02  loss=4.20     active=6151  feature_norm=28.50\n",
      "Iter 406 time=0.02  loss=4.20     active=6150  feature_norm=28.50\n",
      "Iter 407 time=0.02  loss=4.20     active=6150  feature_norm=28.50\n",
      "Iter 408 time=0.02  loss=4.20     active=6149  feature_norm=28.50\n",
      "Iter 409 time=0.02  loss=4.20     active=6149  feature_norm=28.50\n",
      "Iter 410 time=0.02  loss=4.20     active=6149  feature_norm=28.50\n",
      "Iter 411 time=0.02  loss=4.20     active=6148  feature_norm=28.50\n",
      "Iter 412 time=0.02  loss=4.20     active=6147  feature_norm=28.50\n",
      "Iter 413 time=0.02  loss=4.20     active=6147  feature_norm=28.50\n",
      "Iter 414 time=0.02  loss=4.20     active=6152  feature_norm=28.50\n",
      "Iter 415 time=0.02  loss=4.20     active=6151  feature_norm=28.50\n",
      "Iter 416 time=0.02  loss=4.20     active=6152  feature_norm=28.50\n",
      "Iter 417 time=0.02  loss=4.20     active=6152  feature_norm=28.50\n",
      "Iter 418 time=0.02  loss=4.20     active=6152  feature_norm=28.50\n",
      "Iter 419 time=0.02  loss=4.20     active=6153  feature_norm=28.50\n",
      "Iter 420 time=0.02  loss=4.20     active=6153  feature_norm=28.50\n",
      "Iter 421 time=0.02  loss=4.20     active=6153  feature_norm=28.50\n",
      "Iter 422 time=0.02  loss=4.20     active=6153  feature_norm=28.50\n",
      "Iter 423 time=0.02  loss=4.20     active=6152  feature_norm=28.50\n",
      "Iter 424 time=0.02  loss=4.20     active=6152  feature_norm=28.50\n",
      "Iter 425 time=0.01  loss=4.20     active=6150  feature_norm=28.50\n",
      "Iter 426 time=0.02  loss=4.20     active=6149  feature_norm=28.50\n",
      "Iter 427 time=0.02  loss=4.20     active=6150  feature_norm=28.50\n",
      "Iter 428 time=0.02  loss=4.20     active=6149  feature_norm=28.50\n",
      "Iter 429 time=0.02  loss=4.20     active=6148  feature_norm=28.50\n",
      "Iter 430 time=0.02  loss=4.20     active=6149  feature_norm=28.50\n",
      "Iter 431 time=0.02  loss=4.20     active=6149  feature_norm=28.50\n",
      "Iter 432 time=0.02  loss=4.20     active=6149  feature_norm=28.50\n",
      "Iter 433 time=0.02  loss=4.20     active=6149  feature_norm=28.50\n",
      "Iter 434 time=0.02  loss=4.20     active=6149  feature_norm=28.50\n",
      "Iter 435 time=0.02  loss=4.20     active=6145  feature_norm=28.50\n",
      "Iter 436 time=0.02  loss=4.20     active=6155  feature_norm=28.50\n",
      "Iter 437 time=0.02  loss=4.20     active=6155  feature_norm=28.50\n",
      "Iter 438 time=0.02  loss=4.20     active=6155  feature_norm=28.50\n",
      "Iter 439 time=0.02  loss=4.20     active=6154  feature_norm=28.50\n",
      "Iter 440 time=0.02  loss=4.20     active=6153  feature_norm=28.50\n",
      "Iter 441 time=0.02  loss=4.20     active=6152  feature_norm=28.50\n",
      "Iter 442 time=0.02  loss=4.20     active=6152  feature_norm=28.50\n",
      "Iter 443 time=0.02  loss=4.20     active=6152  feature_norm=28.50\n",
      "Iter 444 time=0.02  loss=4.20     active=6152  feature_norm=28.50\n",
      "Iter 445 time=0.02  loss=4.20     active=6152  feature_norm=28.50\n",
      "Iter 446 time=0.02  loss=4.20     active=6152  feature_norm=28.50\n",
      "Iter 447 time=0.02  loss=4.20     active=6151  feature_norm=28.50\n",
      "Iter 448 time=0.02  loss=4.20     active=6152  feature_norm=28.50\n",
      "Iter 449 time=0.02  loss=4.20     active=6153  feature_norm=28.50\n",
      "Iter 450 time=0.02  loss=4.20     active=6153  feature_norm=28.50\n",
      "Iter 451 time=0.02  loss=4.20     active=6152  feature_norm=28.50\n",
      "Iter 452 time=0.02  loss=4.20     active=6152  feature_norm=28.50\n",
      "Iter 453 time=0.02  loss=4.20     active=6152  feature_norm=28.50\n",
      "Iter 454 time=0.02  loss=4.20     active=6150  feature_norm=28.50\n",
      "Iter 455 time=0.02  loss=4.20     active=6150  feature_norm=28.50\n",
      "Iter 456 time=0.02  loss=4.20     active=6150  feature_norm=28.50\n",
      "Iter 457 time=0.02  loss=4.20     active=6150  feature_norm=28.50\n",
      "Iter 458 time=0.02  loss=4.20     active=6150  feature_norm=28.50\n",
      "Iter 459 time=0.02  loss=4.20     active=6150  feature_norm=28.50\n",
      "Iter 460 time=0.02  loss=4.20     active=6150  feature_norm=28.50\n",
      "Iter 461 time=0.02  loss=4.20     active=6150  feature_norm=28.50\n",
      "Iter 462 time=0.02  loss=4.20     active=6138  feature_norm=28.50\n",
      "Iter 463 time=0.02  loss=4.20     active=6138  feature_norm=28.50\n",
      "Iter 464 time=0.02  loss=4.20     active=6139  feature_norm=28.50\n",
      "Iter 465 time=0.02  loss=4.20     active=6139  feature_norm=28.50\n",
      "Iter 466 time=0.02  loss=4.20     active=6138  feature_norm=28.50\n",
      "Iter 467 time=0.02  loss=4.20     active=6138  feature_norm=28.50\n",
      "Iter 468 time=0.02  loss=4.20     active=6137  feature_norm=28.50\n",
      "Iter 469 time=0.02  loss=4.20     active=6135  feature_norm=28.50\n",
      "Iter 470 time=0.02  loss=4.20     active=6134  feature_norm=28.50\n",
      "Iter 471 time=0.02  loss=4.20     active=6134  feature_norm=28.50\n",
      "Iter 472 time=0.02  loss=4.20     active=6134  feature_norm=28.50\n",
      "Iter 473 time=0.02  loss=4.20     active=6134  feature_norm=28.50\n",
      "Iter 474 time=0.02  loss=4.20     active=6133  feature_norm=28.50\n",
      "Iter 475 time=0.02  loss=4.20     active=6133  feature_norm=28.50\n",
      "Iter 476 time=0.02  loss=4.20     active=6133  feature_norm=28.50\n",
      "Iter 477 time=0.02  loss=4.20     active=6132  feature_norm=28.50\n",
      "Iter 478 time=0.02  loss=4.20     active=6137  feature_norm=28.50\n",
      "Iter 479 time=0.02  loss=4.20     active=6137  feature_norm=28.50\n",
      "Iter 480 time=0.02  loss=4.20     active=6137  feature_norm=28.50\n",
      "Iter 481 time=0.02  loss=4.20     active=6138  feature_norm=28.50\n",
      "Iter 482 time=0.02  loss=4.20     active=6132  feature_norm=28.50\n",
      "Iter 483 time=0.02  loss=4.20     active=6131  feature_norm=28.50\n",
      "Iter 484 time=0.02  loss=4.20     active=6130  feature_norm=28.50\n",
      "Iter 485 time=0.02  loss=4.20     active=6129  feature_norm=28.50\n",
      "Iter 486 time=0.02  loss=4.20     active=6130  feature_norm=28.50\n",
      "Iter 487 time=0.02  loss=4.20     active=6129  feature_norm=28.50\n",
      "Iter 488 time=0.02  loss=4.20     active=6129  feature_norm=28.50\n",
      "Iter 489 time=0.02  loss=4.20     active=6129  feature_norm=28.50\n",
      "Iter 490 time=0.02  loss=4.20     active=6128  feature_norm=28.50\n",
      "Iter 491 time=0.02  loss=4.20     active=6128  feature_norm=28.50\n",
      "Iter 492 time=0.02  loss=4.20     active=6128  feature_norm=28.50\n",
      "Iter 493 time=0.02  loss=4.20     active=6128  feature_norm=28.50\n",
      "Iter 494 time=0.02  loss=4.20     active=6128  feature_norm=28.50\n",
      "Iter 495 time=0.02  loss=4.20     active=6128  feature_norm=28.50\n",
      "Iter 496 time=0.02  loss=4.20     active=6128  feature_norm=28.50\n",
      "Iter 497 time=0.02  loss=4.20     active=6128  feature_norm=28.49\n",
      "Iter 498 time=0.02  loss=4.20     active=6128  feature_norm=28.49\n",
      "Iter 499 time=0.02  loss=4.20     active=6127  feature_norm=28.49\n",
      "Iter 500 time=0.02  loss=4.20     active=6127  feature_norm=28.49\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 7.246\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 6127 (28381)\n",
      "Number of active attributes: 2374 (2897)\n",
      "Number of active labels: 140 (140)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.006\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crf2 = CRF(algorithm='lbfgs', verbose=1, c1=0.001, c2=0.001, num_memories=9, linesearch='MoreThuente', \n",
    "           max_iterations=500, all_possible_transitions=True)\n",
    "\n",
    "try:\n",
    "    crf2.fit(train_copy, train_tags)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "156da482-3102-4ed1-a2ff-d97357321800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2860824742268041\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = crf2.predict(dev_dicts)\n",
    "print(accuracy_score(flatten(dev_tags), flatten(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6aaf0f58-e869-4684-a457-531f54a72989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_predictions(path: str, lang: str, preds, pred_input_data):\n",
    "    \"\"\"Writes the predictions to a new file, which uses the file in `path` as input\"\"\"\n",
    "    def create_gloss_line(glosses, transcription_tokens):\n",
    "        \"\"\"\n",
    "        Write a gloss for each transcription token\n",
    "        We should never write more glosses than there are tokens\n",
    "        If tokens are segmented, write morphemes together\n",
    "        \"\"\"\n",
    "        output_line = ''\n",
    "        for (token, gloss) in zip(transcription_tokens, glosses):\n",
    "            if token[0] == '-':\n",
    "                output_line += f\"-{gloss}\"\n",
    "            else:\n",
    "                output_line += f\" {gloss}\"\n",
    "        return output_line\n",
    "\n",
    "    decoded_preds = preds\n",
    "    next_line = 0\n",
    "    with open(path, 'r') as input:\n",
    "        with open(lang + '_output_preds', 'w') as output:\n",
    "            for line in input:\n",
    "                line_prefix = line[:2]\n",
    "                if line_prefix == '\\\\g':\n",
    "                    output_line = create_gloss_line(glosses=decoded_preds[next_line], transcription_tokens=pred_input_data[next_line])\n",
    "                    output_line = line_prefix + output_line + '\\n'\n",
    "                    output.write(output_line)\n",
    "                    next_line += 1\n",
    "                else:\n",
    "                    output.write(line)\n",
    "    print(f\"Predictions written to ./{lang}_output_preds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1368c36-0efc-45a4-800d-8eb2839850c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions written to ./Gitksan_output_preds\n"
     ]
    }
   ],
   "source": [
    "write_predictions(dev_path, 'Gitksan', y_pred, gits_dev_tokens)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "18bcbc1c-5714-41ac-9b52-e756c10173bf",
   "metadata": {},
   "source": [
    "(base) ananyaapparaju@Ananyas-MacBook-Pro ~/Downloads/2023glossingST (main)\n",
    "$ python3 eval.py --pred ./Gitksan_output_preds --gold ./git-dev-track2-uncovered\n",
    "{\n",
    "    \"bleu\": 0.055059999227523804,\n",
    "    \"classes\": {\n",
    "        \"gram\": {\n",
    "            \"f1\": 0.2224694104560623,\n",
    "            \"prec\": 0.199203187250996,\n",
    "            \"rec\": 0.2518891687657431\n",
    "        },\n",
    "        \"stem\": {\n",
    "            \"f1\": 0.10774410774410774,\n",
    "            \"prec\": 0.17777777777777778,\n",
    "            \"rec\": 0.07729468599033816\n",
    "        }\n",
    "    },\n",
    "    \"morpheme_level\": {\n",
    "        \"accuracy\": 0.19205298013245034,\n",
    "        \"average_accuracy\": 0.22432210869345542\n",
    "    },\n",
    "    \"word_level\": {\n",
    "        \"accuracy\": 0.2860824742268041,\n",
    "        \"average_accuracy\": 0.3131745082402977\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "git\t\n",
    "morpheme\n",
    "Ovr: 30.0\n",
    "Avg: 30.2\n",
    "\n",
    "word\n",
    "Ovr: 25.0\n",
    "Avg: 25.7\n",
    "\n",
    "bleu\n",
    "14.2\n",
    "\n",
    "stems\n",
    "P: 37.8\n",
    "R: 15.0\n",
    "F1: 21.5\n",
    "\n",
    "grams\n",
    "P: 41.8\n",
    "R: 37.8\n",
    "F1: 39.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfefbb0-de4e-4b5b-9275-a0bb484c682d",
   "metadata": {},
   "source": [
    "### Adding BIES and IOB tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "74bd557f-da8e-41ab-b66e-402859a62730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'nakwhl\", 'hlidaa', \"'wihl\", \"wili'y\", 'g̲oohl', 'wag̲ayt', 'andoosda', 'wil', 'jok̲hl', 'amxsiwaa.']\n",
      "[\"'nakw-hl\", 'hli-daa', \"'wihl\", \"wil-'y\", 'g̲oo-hl', 'wag̲ayt', 'an-doosda', 'wil', 'jok̲-hl', 'amxsiwaa']\n"
     ]
    }
   ],
   "source": [
    "print(gits_train_tokens[0])\n",
    "print(gits_morphemes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "56f8a312-cdc6-4245-9b0f-e507e41422ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "gits_morph_MO = defaultdict(list)\n",
    "\n",
    "for i, morph_list in enumerate(gits_morphemes):\n",
    "    inner_list = []\n",
    "    for morph in morph_list:\n",
    "        if '-' in morph:\n",
    "            inner_list.append('M')\n",
    "        else:\n",
    "            inner_list.append('O')\n",
    "    gits_morph_MO[i] = inner_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6ef555aa-c0a0-4438-ae8e-a4adaa2c4119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['M', 'M', 'O', 'M', 'M', 'O', 'M', 'O', 'M', 'O'],\n",
       " ['O', 'O', 'M', 'M', 'M', 'O', 'M'],\n",
       " ['O', 'M', 'M', 'O'],\n",
       " ['O', 'O', 'M', 'O', 'O', 'O', 'M', 'M', 'M', 'M', 'M', 'O', 'O', 'M'],\n",
       " ['O', 'O', 'O', 'O', 'M', 'O', 'M', 'M', 'O'],\n",
       " ['O', 'O', 'M', 'O', 'O', 'M', 'M', 'O'],\n",
       " ['O', 'O', 'M', 'M', 'O', 'O', 'M'],\n",
       " ['O', 'M', 'O', 'M', 'M', 'O', 'O', 'M', 'M', 'M', 'M', 'M'],\n",
       " ['O', 'M', 'M', 'M'],\n",
       " ['O', 'M', 'M'],\n",
       " ['O', 'M', 'O', 'O', 'M'],\n",
       " ['O', 'M', 'M', 'M', 'M', 'O'],\n",
       " ['O', 'M', 'O', 'M', 'O', 'O', 'M', 'M', 'O', 'O'],\n",
       " ['O', 'M', 'M', 'O', 'M', 'M', 'O'],\n",
       " ['O', 'O', 'M', 'O', 'M', 'O', 'M', 'O', 'M', 'O'],\n",
       " ['O', 'O', 'M', 'O', 'O', 'O', 'M', 'M', 'O', 'O', 'M'],\n",
       " ['O', 'O', 'O', 'M', 'O', 'M'],\n",
       " ['M', 'O', 'O', 'M'],\n",
       " ['O', 'O', 'M', 'O', 'M', 'O', 'O', 'M', 'O', 'M', 'M'],\n",
       " ['M', 'O', 'M', 'M', 'M', 'O', 'M', 'M', 'O', 'O', 'M', 'M', 'O'],\n",
       " ['O', 'M', 'O', 'O', 'M'],\n",
       " ['M', 'M', 'O', 'M', 'M', 'O', 'O', 'M'],\n",
       " ['O', 'M', 'M', 'O', 'O', 'O', 'M', 'M', 'M', 'O'],\n",
       " ['O', 'M', 'O', 'O', 'M', 'M'],\n",
       " ['O', 'M', 'O', 'O', 'M'],\n",
       " ['O', 'O', 'M', 'O', 'M', 'M', 'O', 'O', 'O', 'M', 'M', 'O', 'M'],\n",
       " ['O', 'O', 'M', 'M', 'M', 'M', 'M', 'O', 'O'],\n",
       " ['M', 'M', 'O', 'O', 'O', 'O', 'O', 'M', 'O', 'M', 'M'],\n",
       " ['O', 'M', 'M', 'M', 'O', 'M', 'M', 'M', 'O', 'O', 'O'],\n",
       " ['O', 'M', 'M', 'O', 'M', 'M', 'O', 'M', 'O', 'M', 'M'],\n",
       " ['O', 'M', 'O', 'O', 'O', 'O', 'M', 'M', 'M', 'O', 'O']]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gits_morph_BIES = defaultdict(list)\n",
    " \n",
    "MO_tags = list(gits_morph_MO.values())\n",
    "\n",
    "B = \"BEGIN\"\n",
    "I = \"INSIDE\"\n",
    "E = \"END\"\n",
    "S = \"SINGLE\"\n",
    "\n",
    "for morpheme_list, tag_list in zip(gits_morphemes, MO_tags):\n",
    "    BIES_list = []\n",
    "    for morpheme, tag in zip(morpheme_list, tag_list):\n",
    "        if tag == 'O':\n",
    "            for i in range(len(morpheme)):\n",
    "                if i == 0:\n",
    "                    BIES_list.append((morpheme[i], B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8804e8d2-5f4d-4bd5-b23b-34f9ad6184a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
